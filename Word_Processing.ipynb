{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "328e3219-e1c7-4a69-b556-1c62f024a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bill Nicholson\n",
    "# nicholdw@ucmail.uc.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdee4ca3-d524-46dc-99ad-d22ac77eac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4caf873-5d02-4178-9ef8-fe413c08d1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word_Processing:\n",
    "    def split_text(text):\n",
    "        \"\"\"\n",
    "        Split a string into words.\n",
    "        @param text String: The text to process\n",
    "        @return list: The individual words\n",
    "        \"\"\"\n",
    "        # Replace punctuation with spaces\n",
    "        #punctuation = \"!@#$%^&*().,?\\\"';:~`\"\n",
    "        translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "        text = text.translate(translator)\n",
    "\n",
    "        words = text.split()\n",
    "        words = [word.upper() for word in words]\n",
    "        return words\n",
    "    \n",
    "    def load_dictionary():\n",
    "        \"\"\"\n",
    "        Read the words.txt file into a dictionary.\n",
    "        See https://github.com/dwyl/english-words for the original words.txt file.\n",
    "        @return the dictionary. Key is the word (all upper case), value is the length of the word\n",
    "        \"\"\"\n",
    "        with open(\"words.txt\", 'r') as file:\n",
    "            lines_dict = {}\n",
    "            line_number = 1\n",
    "            for line in file:\n",
    "                lines_dict[line.strip().upper()] = len(line.strip())\n",
    "        return lines_dict\n",
    "\n",
    "    def find_word(questions, word):\n",
    "        \"\"\"\n",
    "        Look for a word across all the questions\n",
    "        @param questions list of dictionaries: The questions to be searched\n",
    "        @param word string: the word to look for\n",
    "        @return list of dictionaries: all questions that contain the word\n",
    "        \"\"\"\n",
    "        found = []\n",
    "        for question in questions:\n",
    "            if word.upper() in question[\"input\"].upper():\n",
    "                found.append(question)\n",
    "        return found\n",
    "\n",
    "    def compute_word_frequency(text, force_to_upper_case = True, min_length = 1):\n",
    "        \"\"\"\n",
    "        @param text String: The text to process\n",
    "        @param force_to_upper_case bool: convert all words to upper case so 'the' is the same as 'The', etc.\n",
    "        @param min_length int: Ignore words shorter than min_length\n",
    "        @return (Dictionary, count): ({key is word, value is frequency of that word}, count is the number of total words in text)\n",
    "        \"\"\"\n",
    "        word_frequency = dict()\n",
    "        count = 0\n",
    "        for word in text.replace(',', ' ').replace(\"\\n\", \" \").split():\n",
    "            count += 1\n",
    "            word = word.strip()\n",
    "            if len(word) >= min_length:\n",
    "                if force_to_upper_case:\n",
    "                    word = word.upper()\n",
    "                try:\n",
    "                    word_frequency[word] += 1\n",
    "                except:\n",
    "                    word_frequency[word] = 1\n",
    "        return (word_frequency, count)\n",
    "    \n",
    "    def compute_longest_words(text, force_to_upper_case = True, min_length = 0):\n",
    "        \"\"\"\n",
    "        @param text String: The text to process\n",
    "        @param force_to_upper_case: convert all words to upper case so 'the' is the same as 'The', etc.\n",
    "        @param min_length int: Use this as the minumum length for words to find rather than computing a maximum length and using that, If 0, compute the max_length\n",
    "        @return (Dictionary, count): ({key is word, value is frequency of that word}, count is the number of total words in text)\n",
    "        \"\"\"\n",
    "        word_frequency = dict()\n",
    "        count = 0\n",
    "        if min_length == 0:\n",
    "            max_length = 0\n",
    "            # Find the max length across all words in the text\n",
    "            for word in text.replace(',', ' ').split():\n",
    "                word = word.strip()\n",
    "                if len(word) > max_length:\n",
    "                    max_length = len(word)\n",
    "        else:\n",
    "            max_length = min_length\n",
    "\n",
    "        # Find all words with length == max_length, store in our dictionary\n",
    "        #for word in text.replace([',', '?', '!', '.'], ' ').split():\n",
    "        for word in text.replace(',', ' ').split():\n",
    "            count += 1\n",
    "            word = word.strip()\n",
    "            if len(word) >= max_length:\n",
    "                if force_to_upper_case:\n",
    "                    word = word.upper()\n",
    "                try:\n",
    "                    word_frequency[word] += 1\n",
    "                except:\n",
    "                    word_frequency[word] = 1\n",
    "        return (word_frequency, count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
